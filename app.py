import streamlit as st
from utils import AIModel, format_chat_history
from config import PAGE_CONFIG, PRESET_MODELS, DEFAULT_API_CONFIG

# é…ç½®é¡µé¢
st.set_page_config(**PAGE_CONFIG)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "api_config" not in st.session_state:
    st.session_state.api_config = DEFAULT_API_CONFIG.copy()
    st.session_state.api_config.update({
        "api_key": "",
        "model": list(PRESET_MODELS.values())[0]  # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹
    })

if "custom_models" not in st.session_state:
    st.session_state.custom_models = {}

if "ai_model" not in st.session_state:
    st.session_state.ai_model = AIModel(st.session_state.api_config)

if "current_request" not in st.session_state:
    st.session_state.current_request = None

# é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– AIæ€è€ƒæ¨ç†åŠ©æ‰‹")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("ğŸ› ï¸ æ¨¡å‹é…ç½®")
    
    # APIè®¾ç½®
    with st.expander("APIè®¾ç½®", expanded=True):
        # API Base URL
        base_url = st.text_input(
            "API Base URL",
            value=st.session_state.api_config["base_url"],
            help="è®¾ç½®APIåŸºç¡€åœ°å€"
        )
        
        # API Key
        api_key = st.text_input(
            "API Key",
            value=st.session_state.api_config["api_key"],
            type="password",
            help="è¾“å…¥æ‚¨çš„APIå¯†é’¥"
        )
        
        if base_url != st.session_state.api_config["base_url"] or \
           api_key != st.session_state.api_config["api_key"]:
            st.session_state.api_config.update({
                "base_url": base_url,
                "api_key": api_key
            })
            st.session_state.ai_model.update_config(st.session_state.api_config)
    
    # æ¨¡å‹é€‰æ‹©
    with st.expander("æ¨¡å‹é€‰æ‹©", expanded=True):
        # é¢„è®¾æ¨¡å‹
        st.subheader("é¢„è®¾æ¨¡å‹")
        selected_preset = st.selectbox(
            "é€‰æ‹©é¢„è®¾æ¨¡å‹",
            list(PRESET_MODELS.keys()),
            format_func=lambda x: f"ğŸ“¦ {x}",
            help="é€‰æ‹©è¦ä½¿ç”¨çš„é¢„è®¾æ¨¡å‹"
        )
        
        # è‡ªå®šä¹‰æ¨¡å‹
        st.subheader("è‡ªå®šä¹‰æ¨¡å‹")
        custom_model_name = st.text_input("æ¨¡å‹åç§°", key="new_model_name")
        custom_model_id = st.text_input("æ¨¡å‹ID", key="new_model_id")
        
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("â• æ·»åŠ æ¨¡å‹", help="æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹"):
                if custom_model_name and custom_model_id:
                    st.session_state.custom_models[custom_model_name] = custom_model_id
                    st.success(f"å·²æ·»åŠ æ¨¡å‹: {custom_model_name}")
                else:
                    st.warning("è¯·å¡«å†™æ¨¡å‹åç§°å’ŒID")
        
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å…¨éƒ¨", help="æ¸…é™¤æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å‹"):
                st.session_state.custom_models = {}
                st.success("å·²æ¸…é™¤æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å‹")
        
        # æ˜¾ç¤ºç°æœ‰çš„è‡ªå®šä¹‰æ¨¡å‹
        if st.session_state.custom_models:
            st.subheader("å·²æ·»åŠ çš„è‡ªå®šä¹‰æ¨¡å‹")
            for name, model_id in st.session_state.custom_models.items():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.text(f"ğŸ“ {name}: {model_id}")
                with col2:
                    if st.button("åˆ é™¤", key=f"del_{name}", help=f"åˆ é™¤æ¨¡å‹ {name}"):
                        del st.session_state.custom_models[name]
                        st.success(f"å·²åˆ é™¤æ¨¡å‹: {name}")
                        st.experimental_rerun()
        
        # åˆå¹¶æ‰€æœ‰æ¨¡å‹é€‰é¡¹
        all_models = {**PRESET_MODELS, **st.session_state.custom_models}
        selected_model = all_models[selected_preset]
        
        if selected_model != st.session_state.api_config["model"]:
            st.session_state.api_config["model"] = selected_model
            st.session_state.ai_model.update_config(st.session_state.api_config)
    
    # é«˜çº§è®¾ç½®
    with st.expander("é«˜çº§è®¾ç½®"):
        max_tokens = st.number_input(
            "æœ€å¤§ç”Ÿæˆé•¿åº¦",
            min_value=1,
            max_value=130000,
            value=st.session_state.api_config.get("max_tokens", 8192),
            help="è®¾ç½®ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦"
        )
        
        if max_tokens != st.session_state.api_config.get("max_tokens"):
            st.session_state.api_config["max_tokens"] = max_tokens
            st.session_state.ai_model.update_config(st.session_state.api_config)
    
    # æ·»åŠ åˆ†éš”çº¿
    st.divider()
    
    # æ¸…ç©ºå¯¹è¯æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", type="secondary", help="æ¸…é™¤æ‰€æœ‰å¯¹è¯è®°å½•"):
        st.session_state.chat_history = []
        st.session_state.current_request = None
        st.experimental_rerun()

def process_ai_response(prompt, chat_history):
    """å¤„ç†AIå“åº”çš„å‡½æ•°"""
    # æ£€æŸ¥APIé…ç½®
    if not st.session_state.api_config.get("api_key"):
        st.error("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®API Key")
        return
    
    # åˆ›å»ºå ä½ç¬¦
    reasoning_placeholder = st.empty()
    response_placeholder = st.empty()
    
    # ç”¨äºç´¯ç§¯å†…å®¹
    full_reasoning = ""
    full_response = ""
    has_error = False
    
    # æ˜¾ç¤ºåˆå§‹çŠ¶æ€
    with reasoning_placeholder.expander("æ­£åœ¨æ€è€ƒ...", expanded=True):
        reasoning_container = st.empty()
    
    response_container = response_placeholder.empty()
    
    # å¤„ç†æµå¼å“åº”
    for chunk in st.session_state.ai_model.generate_response_stream(
        prompt, 
        chat_history
    ):
        if chunk["type"] == "reasoning":
            full_reasoning += chunk["content"]
            with reasoning_placeholder.expander("æ€è€ƒè¿‡ç¨‹", expanded=True):
                reasoning_container.markdown(f"### ğŸ¤” æ€è€ƒè¿‡ç¨‹\n{full_reasoning}")
        
        elif chunk["type"] == "response":
            full_response += chunk["content"]
            response_container.markdown(f"### ğŸ’¡ å›ç­”\n{full_response}")
        
        elif chunk["type"] == "complete":
            # æ›´æ–°ä¸ºæœ€ç»ˆçŠ¶æ€
            with reasoning_placeholder.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
                reasoning_container.markdown(f"### ğŸ¤” æ€è€ƒè¿‡ç¨‹\n{chunk['content']['reasoning']}")
            response_container.markdown(f"### ğŸ’¡ å›ç­”\n{chunk['content']['response']}")
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": chunk["content"]
            })
            # æ¸…é™¤å½“å‰è¯·æ±‚
            st.session_state.current_request = None
            
        elif chunk["type"] == "error":
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            has_error = True
            with reasoning_placeholder.expander("æ€è€ƒè¿‡ç¨‹å‡ºé”™", expanded=True):
                reasoning_container.error(chunk["content"]["reasoning"])
            response_container.error(chunk["content"]["response"])
            
            # æ·»åŠ é‡è¯•æŒ‰é’®
            col1, col2 = response_container.columns([3, 1])
            with col2:
                if st.button("ğŸ”„ é‡è¯•", key="retry_button"):
                    # ä¿å­˜å½“å‰è¯·æ±‚ä¿¡æ¯ä»¥ä¾›é‡è¯•
                    st.session_state.current_request = {
                        "prompt": prompt,
                        "chat_history": chat_history
                    }
                    st.experimental_rerun()

    return has_error

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        # å¦‚æœæ˜¯AIå›å¤ï¼Œæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œå›ç­”
        if message["role"] == "assistant" and isinstance(message["content"], dict):
            # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„åŒºåŸŸæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            with st.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown("### ğŸ¤” æ€è€ƒè¿‡ç¨‹")
                st.markdown(message["content"]["reasoning"])
            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            st.markdown("### ğŸ’¡ å›ç­”")
            st.markdown(message["content"]["response"])
        else:
            st.write(message["content"])

# æ£€æŸ¥æ˜¯å¦æœ‰å¾…é‡è¯•çš„è¯·æ±‚
if st.session_state.current_request:
    with st.chat_message("assistant"):
        process_ai_response(
            st.session_state.current_request["prompt"],
            st.session_state.current_request["chat_history"]
        )

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.write(prompt)
    
    # æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹
    with st.chat_message("assistant"):
        process_ai_response(prompt, st.session_state.chat_history[:-1]) 