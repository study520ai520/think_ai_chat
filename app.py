import streamlit as st
from utils import AIModel, format_chat_history
from config import PAGE_CONFIG, MODEL_OPTIONS, PARAMETER_RANGES

# é…ç½®é¡µé¢
st.set_page_config(**PAGE_CONFIG)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "ai_model" not in st.session_state:
    st.session_state.ai_model = AIModel()

# é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– AIæ€è€ƒæ¨ç†åŠ©æ‰‹")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("æ¨¡å‹é…ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    selected_model_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        list(MODEL_OPTIONS.keys()),
        help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
    )
    st.session_state.ai_model.config["model"] = MODEL_OPTIONS[selected_model_name]
    
    # å‚æ•°è°ƒæ•´
    st.subheader("å‚æ•°è®¾ç½®")
    for param, config in PARAMETER_RANGES.items():
        if config["type"] == "float":
            value = st.slider(
                f"{param} - {config['description']}",
                min_value=float(config['min']),
                max_value=float(config['max']),
                value=float(config['default']),
                step=float(config['step']),
                help=config['description']
            )
        else:  # intç±»å‹
            value = st.slider(
                f"{param} - {config['description']}",
                min_value=int(config['min']),
                max_value=int(config['max']),
                value=int(config['default']),
                step=int(config['step']),
                help=config['description']
            )
        st.session_state.ai_model.config[param] = value
    
    # æ·»åŠ åˆ†éš”çº¿
    st.divider()
    
    # æ¸…ç©ºå¯¹è¯æŒ‰é’®
    if st.button("æ¸…ç©ºå¯¹è¯å†å²", type="secondary"):
        st.session_state.chat_history = []
        st.experimental_rerun()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        # å¦‚æœæ˜¯AIå›å¤ï¼Œæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œå›ç­”
        if message["role"] == "assistant" and isinstance(message["content"], dict):
            # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„åŒºåŸŸæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            with st.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown("### ğŸ¤” æ€è€ƒè¿‡ç¨‹")
                st.markdown(message["content"]["reasoning"])
            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            st.markdown("### ğŸ’¡ å›ç­”")
            st.markdown(message["content"]["response"])
        else:
            st.write(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.write(prompt)
    
    # æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹
    with st.chat_message("assistant"):
        with st.spinner("AIæ­£åœ¨æ€è€ƒ..."):
            response = st.session_state.ai_model.generate_response(
                prompt, 
                st.session_state.chat_history[:-1]
            )
            
            # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„åŒºåŸŸæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            with st.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown("### ğŸ¤” æ€è€ƒè¿‡ç¨‹")
                st.markdown(response["reasoning"])
            
            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            st.markdown("### ğŸ’¡ å›ç­”")
            st.markdown(response["response"])
            
            # æ·»åŠ AIå›å¤åˆ°å†å²
            st.session_state.chat_history.append({"role": "assistant", "content": response}) 