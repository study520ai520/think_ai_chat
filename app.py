import streamlit as st
from utils import AIModel, format_chat_history
from config import PAGE_CONFIG, MODEL_OPTIONS, PARAMETER_RANGES, DEFAULT_API_KEY

# é…ç½®é¡µé¢
st.set_page_config(**PAGE_CONFIG)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "api_key" not in st.session_state:
    st.session_state.api_key = DEFAULT_API_KEY

if "ai_model" not in st.session_state:
    st.session_state.ai_model = AIModel()

# é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– AIæ€è€ƒæ¨ç†åŠ©æ‰‹")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("æ¨¡å‹é…ç½®")
    
    # API Keyè¾“å…¥
    api_key = st.text_input(
        "API Key",
        value=st.session_state.api_key,
        type="password",
        help="è¾“å…¥æ‚¨çš„DeepSeek API Keyï¼Œå¦‚æœä¸å¡«å†™åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„é»˜è®¤å€¼"
    )
    
    # å¦‚æœAPI Keyå‘ç”Ÿå˜åŒ–ï¼Œæ›´æ–°æ¨¡å‹é…ç½®
    if api_key != st.session_state.api_key:
        st.session_state.api_key = api_key
        st.session_state.ai_model.update_api_key(api_key if api_key else DEFAULT_API_KEY)
    
    # æ¨¡å‹é€‰æ‹©
    selected_model_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        list(MODEL_OPTIONS.keys()),
        help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
    )
    st.session_state.ai_model.config["model"] = MODEL_OPTIONS[selected_model_name]
    
    # å‚æ•°è°ƒæ•´
    st.subheader("å‚æ•°è®¾ç½®")
    for param, config in PARAMETER_RANGES.items():
        if config["type"] == "float":
            value = st.slider(
                f"{param} - {config['description']}",
                min_value=float(config['min']),
                max_value=float(config['max']),
                value=float(config['default']),
                step=float(config['step']),
                help=config['description']
            )
        else:  # intç±»å‹
            value = st.slider(
                f"{param} - {config['description']}",
                min_value=int(config['min']),
                max_value=int(config['max']),
                value=int(config['default']),
                step=int(config['step']),
                help=config['description']
            )
        st.session_state.ai_model.config[param] = value
    
    # æ·»åŠ åˆ†éš”çº¿
    st.divider()
    
    # æ¸…ç©ºå¯¹è¯æŒ‰é’®
    if st.button("æ¸…ç©ºå¯¹è¯å†å²", type="secondary"):
        st.session_state.chat_history = []
        st.experimental_rerun()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        # å¦‚æœæ˜¯AIå›å¤ï¼Œæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œå›ç­”
        if message["role"] == "assistant" and isinstance(message["content"], dict):
            # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„åŒºåŸŸæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            with st.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown("### ğŸ¤” æ€è€ƒè¿‡ç¨‹")
                st.markdown(message["content"]["reasoning"])
            # æ˜¾ç¤ºæœ€ç»ˆå›ç­”
            st.markdown("### ğŸ’¡ å›ç­”")
            st.markdown(message["content"]["response"])
        else:
            st.write(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ£€æŸ¥æ˜¯å¦æœ‰API Key
    if not st.session_state.api_key:
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ è®¾ç½®API Keyæˆ–åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®DEEPSEEK_API_KEY")
    else:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.write(prompt)
        
        # æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹
        with st.chat_message("assistant"):
            # åˆ›å»ºå ä½ç¬¦
            reasoning_placeholder = st.empty()
            response_placeholder = st.empty()
            
            # ç”¨äºç´¯ç§¯å†…å®¹
            full_reasoning = ""
            full_response = ""
            
            # æ˜¾ç¤ºåˆå§‹çŠ¶æ€
            with reasoning_placeholder.expander("æ­£åœ¨æ€è€ƒ...", expanded=True):
                reasoning_container = st.empty()
            
            response_container = response_placeholder.empty()
            
            # å¤„ç†æµå¼å“åº”
            for chunk in st.session_state.ai_model.generate_response_stream(
                prompt, 
                st.session_state.chat_history[:-1]
            ):
                if chunk["type"] == "reasoning":
                    full_reasoning += chunk["content"]
                    with reasoning_placeholder.expander("æ€è€ƒè¿‡ç¨‹", expanded=True):
                        reasoning_container.markdown(f"### ğŸ¤” æ€è€ƒè¿‡ç¨‹\n{full_reasoning}")
                
                elif chunk["type"] == "response":
                    full_response += chunk["content"]
                    response_container.markdown(f"### ğŸ’¡ å›ç­”\n{full_response}")
                
                elif chunk["type"] == "complete":
                    # æ›´æ–°ä¸ºæœ€ç»ˆçŠ¶æ€
                    with reasoning_placeholder.expander("æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
                        reasoning_container.markdown(f"### ğŸ¤” æ€è€ƒè¿‡ç¨‹\n{chunk['content']['reasoning']}")
                    response_container.markdown(f"### ğŸ’¡ å›ç­”\n{chunk['content']['response']}")
                    
                    # æ·»åŠ åˆ°å†å²è®°å½•
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": chunk["content"]
                    })
                
                elif chunk["type"] == "error":
                    # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    with reasoning_placeholder.expander("æ€è€ƒè¿‡ç¨‹å‡ºé”™", expanded=True):
                        reasoning_container.error(chunk["content"]["reasoning"])
                    response_container.error(chunk["content"]["response"]) 